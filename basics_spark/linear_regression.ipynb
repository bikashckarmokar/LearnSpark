{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTORIAL from https://www.datacamp.com/community/tutorials/apache-spark-tutorial-machine-learning#basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spark context\n",
    "sc = SparkContext(\"local\", \"Linear Regression Model\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "rdd = sc.textFile(\"/home/jmir/ai/learning/spark/cal_housing.data\")\n",
    "\n",
    "# Load the header\n",
    "header = sc.textFile(\"/home/jmir/ai/learning/spark/cal_housing.domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude: continuous.',\n",
       " 'latitude: continuous.',\n",
       " 'housingMedianAge: continuous. ',\n",
       " 'totalRooms: continuous. ',\n",
       " 'totalBedrooms: continuous. ',\n",
       " 'population: continuous. ',\n",
       " 'households: continuous. ',\n",
       " 'medianIncome: continuous. ',\n",
       " 'medianHouseValue: continuous. ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000',\n",
       " '-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000',\n",
       " '-122.240000,37.850000,52.000000,1467.000000,190.000000,496.000000,177.000000,7.257400,352100.000000',\n",
       " '-122.250000,37.850000,52.000000,1274.000000,235.000000,558.000000,219.000000,5.643100,341300.000000',\n",
       " '-122.250000,37.850000,52.000000,1627.000000,280.000000,565.000000,259.000000,3.846200,342200.000000']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split lines on commas (because it is a .csv)\n",
    "rdd = rdd.map(lambda line: line.split(\",\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-122.230000',\n",
       "  '37.880000',\n",
       "  '41.000000',\n",
       "  '880.000000',\n",
       "  '129.000000',\n",
       "  '322.000000',\n",
       "  '126.000000',\n",
       "  '8.325200',\n",
       "  '452600.000000'],\n",
       " ['-122.220000',\n",
       "  '37.860000',\n",
       "  '21.000000',\n",
       "  '7099.000000',\n",
       "  '1106.000000',\n",
       "  '2401.000000',\n",
       "  '1138.000000',\n",
       "  '8.301400',\n",
       "  '358500.000000'],\n",
       " ['-122.240000',\n",
       "  '37.850000',\n",
       "  '52.000000',\n",
       "  '1467.000000',\n",
       "  '190.000000',\n",
       "  '496.000000',\n",
       "  '177.000000',\n",
       "  '7.257400',\n",
       "  '352100.000000'],\n",
       " ['-122.250000',\n",
       "  '37.850000',\n",
       "  '52.000000',\n",
       "  '1274.000000',\n",
       "  '235.000000',\n",
       "  '558.000000',\n",
       "  '219.000000',\n",
       "  '5.643100',\n",
       "  '341300.000000'],\n",
       " ['-122.250000',\n",
       "  '37.850000',\n",
       "  '52.000000',\n",
       "  '1627.000000',\n",
       "  '280.000000',\n",
       "  '565.000000',\n",
       "  '259.000000',\n",
       "  '3.846200',\n",
       "  '342200.000000']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the same first 5 lines\n",
    "rdd.take(5)  # or rdd.first() or rdd.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's construct a SchemaRDD to convert the RDD to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.map(lambda line: Row(longitude=line[0],\n",
    "                              latitude=line[1],\n",
    "                              housingMedianAge=line[2],\n",
    "                              totalRooms=line[3],\n",
    "                              totalBedRooms=line[4],\n",
    "                              population=line[5], \n",
    "                              households=line[6],\n",
    "                              medianIncome=line[7],\n",
    "                              medianHouseValue=line[8])).toDF()  # .toDF() requires a SparkSession (or SQLContext)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n",
      "| households|housingMedianAge| latitude|  longitude|medianHouseValue|medianIncome| population|totalBedRooms| totalRooms|\n",
      "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n",
      "| 126.000000|       41.000000|37.880000|-122.230000|   452600.000000|    8.325200| 322.000000|   129.000000| 880.000000|\n",
      "|1138.000000|       21.000000|37.860000|-122.220000|   358500.000000|    8.301400|2401.000000|  1106.000000|7099.000000|\n",
      "| 177.000000|       52.000000|37.850000|-122.240000|   352100.000000|    7.257400| 496.000000|   190.000000|1467.000000|\n",
      "| 219.000000|       52.000000|37.850000|-122.250000|   341300.000000|    5.643100| 558.000000|   235.000000|1274.000000|\n",
      "| 259.000000|       52.000000|37.850000|-122.250000|   342200.000000|    3.846200| 565.000000|   280.000000|1627.000000|\n",
      "| 193.000000|       52.000000|37.850000|-122.250000|   269700.000000|    4.036800| 413.000000|   213.000000| 919.000000|\n",
      "| 514.000000|       52.000000|37.840000|-122.250000|   299200.000000|    3.659100|1094.000000|   489.000000|2535.000000|\n",
      "| 647.000000|       52.000000|37.840000|-122.250000|   241400.000000|    3.120000|1157.000000|   687.000000|3104.000000|\n",
      "| 595.000000|       42.000000|37.840000|-122.260000|   226700.000000|    2.080400|1206.000000|   665.000000|2555.000000|\n",
      "| 714.000000|       52.000000|37.840000|-122.250000|   261100.000000|    3.691200|1551.000000|   707.000000|3549.000000|\n",
      "| 402.000000|       52.000000|37.850000|-122.260000|   281500.000000|    3.203100| 910.000000|   434.000000|2202.000000|\n",
      "| 734.000000|       52.000000|37.850000|-122.260000|   241800.000000|    3.270500|1504.000000|   752.000000|3503.000000|\n",
      "| 468.000000|       52.000000|37.850000|-122.260000|   213500.000000|    3.075000|1098.000000|   474.000000|2491.000000|\n",
      "| 174.000000|       52.000000|37.840000|-122.260000|   191300.000000|    2.673600| 345.000000|   191.000000| 696.000000|\n",
      "| 620.000000|       52.000000|37.850000|-122.260000|   159200.000000|    1.916700|1212.000000|   626.000000|2643.000000|\n",
      "| 264.000000|       50.000000|37.850000|-122.260000|   140000.000000|    2.125000| 697.000000|   283.000000|1120.000000|\n",
      "| 331.000000|       52.000000|37.850000|-122.270000|   152500.000000|    2.775000| 793.000000|   347.000000|1966.000000|\n",
      "| 303.000000|       52.000000|37.850000|-122.270000|   155500.000000|    2.120200| 648.000000|   293.000000|1228.000000|\n",
      "| 419.000000|       50.000000|37.840000|-122.260000|   158700.000000|    1.991100| 990.000000|   455.000000|2239.000000|\n",
      "| 275.000000|       52.000000|37.840000|-122.270000|   162900.000000|    2.603300| 690.000000|   298.000000|1503.000000|\n",
      "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the df first.\n",
    "# df.first()  or\n",
    "# df.head(20)  or\n",
    "# df.take(20)  or\n",
    "df.show(20)  # this one preserves the crow/column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['households',\n",
       " 'housingMedianAge',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'medianHouseValue',\n",
       " 'medianIncome',\n",
       " 'population',\n",
       " 'totalBedRooms',\n",
       " 'totalRooms']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns  # gives you the columns of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('households', 'string'),\n",
       " ('housingMedianAge', 'string'),\n",
       " ('latitude', 'string'),\n",
       " ('longitude', 'string'),\n",
       " ('medianHouseValue', 'string'),\n",
       " ('medianIncome', 'string'),\n",
       " ('population', 'string'),\n",
       " ('totalBedRooms', 'string'),\n",
       " ('totalRooms', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- households: string (nullable = true)\n",
      " |-- housingMedianAge: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- medianHouseValue: string (nullable = true)\n",
      " |-- medianIncome: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- totalBedRooms: string (nullable = true)\n",
      " |-- totalRooms: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should assign the proper data types to the columns (we don't really want them to be strings!)\n",
    "df = df.withColumn(\"longitude\", df[\"longitude\"].cast(FloatType())) \\\n",
    "   .withColumn(\"latitude\", df[\"latitude\"].cast(FloatType())) \\\n",
    "   .withColumn(\"housingMedianAge\",df[\"housingMedianAge\"].cast(FloatType())) \\\n",
    "   .withColumn(\"totalRooms\", df[\"totalRooms\"].cast(FloatType())) \\\n",
    "   .withColumn(\"totalBedRooms\", df[\"totalBedRooms\"].cast(FloatType())) \\\n",
    "   .withColumn(\"population\", df[\"population\"].cast(FloatType())) \\\n",
    "   .withColumn(\"households\", df[\"households\"].cast(FloatType())) \\\n",
    "   .withColumn(\"medianIncome\", df[\"medianIncome\"].cast(FloatType())) \\\n",
    "   .withColumn(\"medianHouseValue\", df[\"medianHouseValue\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But this method, using a User-Defined Function (UDF) looks prettier\n",
    "def convertColumns(df, names, newType):\n",
    "    for name in names:\n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names to columns:\n",
    "columns = df.columns\n",
    "\n",
    "# Use the function!\n",
    "df = convertColumns(df, columns, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- households: float (nullable = true)\n",
      " |-- housingMedianAge: float (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- medianHouseValue: float (nullable = true)\n",
      " |-- medianIncome: float (nullable = true)\n",
      " |-- population: float (nullable = true)\n",
      " |-- totalBedRooms: float (nullable = true)\n",
      " |-- totalRooms: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|population|totalBedrooms|\n",
      "+----------+-------------+\n",
      "|     322.0|        129.0|\n",
      "|    2401.0|       1106.0|\n",
      "|     496.0|        190.0|\n",
      "|     558.0|        235.0|\n",
      "|     565.0|        280.0|\n",
      "|     413.0|        213.0|\n",
      "|    1094.0|        489.0|\n",
      "|    1157.0|        687.0|\n",
      "|    1206.0|        665.0|\n",
      "|    1551.0|        707.0|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All good now!\n",
    "# Let's launch sql-like queries now\n",
    "df.select(\"population\" ,\"totalBedrooms\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|housingMedianAge|count|\n",
      "+----------------+-----+\n",
      "|            52.0| 1273|\n",
      "|            51.0|   48|\n",
      "|            50.0|  136|\n",
      "|            49.0|  134|\n",
      "|            48.0|  177|\n",
      "|            47.0|  198|\n",
      "|            46.0|  245|\n",
      "|            45.0|  294|\n",
      "|            44.0|  356|\n",
      "|            43.0|  353|\n",
      "|            42.0|  368|\n",
      "|            41.0|  296|\n",
      "|            40.0|  304|\n",
      "|            39.0|  369|\n",
      "|            38.0|  394|\n",
      "|            37.0|  537|\n",
      "|            36.0|  862|\n",
      "|            35.0|  824|\n",
      "|            34.0|  689|\n",
      "|            33.0|  615|\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"housingMedianAge\").count().sort(\"housingMedianAge\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|       households|  housingMedianAge|         latitude|          longitude|  medianHouseValue|      medianIncome|        population|    totalBedRooms|        totalRooms|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|            20640|             20640|            20640|              20640|             20640|             20640|             20640|            20640|             20640|\n",
      "|   mean|499.5396802325581|28.639486434108527|35.63186143109965|-119.56970444871473|206855.81690891474|3.8706710030346416|1425.4767441860465|537.8980135658915|2635.7630813953488|\n",
      "| stddev|382.3297528316098| 12.58555761211163|2.135952380602968|  2.003531742932898|115395.61587441359|1.8998217183639696|  1132.46212176534| 421.247905943133|2181.6152515827944|\n",
      "|    min|              1.0|               1.0|            32.54|            -124.35|           14999.0|            0.4999|               3.0|              1.0|               2.0|\n",
      "|    max|           6082.0|              52.0|            41.95|            -114.31|          500001.0|           15.0001|           35682.0|           6445.0|           39320.0|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------+---------+----------------+------------+----------+-------------+----------+\n",
      "|households|housingMedianAge|latitude|longitude|medianHouseValue|medianIncome|population|totalBedRooms|totalRooms|\n",
      "+----------+----------------+--------+---------+----------------+------------+----------+-------------+----------+\n",
      "|     126.0|            41.0|   37.88|  -122.23|           4.526|      8.3252|     322.0|        129.0|     880.0|\n",
      "|    1138.0|            21.0|   37.86|  -122.22|           3.585|      8.3014|    2401.0|       1106.0|    7099.0|\n",
      "|     177.0|            52.0|   37.85|  -122.24|           3.521|      7.2574|     496.0|        190.0|    1467.0|\n",
      "|     219.0|            52.0|   37.85|  -122.25|           3.413|      5.6431|     558.0|        235.0|    1274.0|\n",
      "|     259.0|            52.0|   37.85|  -122.25|           3.422|      3.8462|     565.0|        280.0|    1627.0|\n",
      "+----------+----------------+--------+---------+----------------+------------+----------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjust the values of \"medianHouseValue\"\n",
    "df = df.withColumn(\"medianHouseValue\", col(\"medianHouseValue\")/100000)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"roomsPerHousehold\", col(\"totalRooms\")/col(\"households\")) \\\n",
    "       .withColumn(\"populationPerHousehold\", col(\"population\")/col(\"households\")) \\\n",
    "       .withColumn(\"bedroomsPerRoom\", col(\"totalBedRooms\")/col(\"totalRooms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(households=126.0, housingMedianAge=41.0, latitude=37.880001068115234, longitude=-122.2300033569336, medianHouseValue=4.526, medianIncome=8.325200080871582, population=322.0, totalBedRooms=129.0, totalRooms=880.0, roomsPerHousehold=6.984126984126984, populationPerHousehold=2.5555555555555554, bedroomsPerRoom=0.14659090909090908)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"medianHouseValue\",\n",
    "            \"totalBedRooms\",\n",
    "            \"population\",\n",
    "            \"medianIncome\",\n",
    "            \"roomsPerHousehold\",\n",
    "            \"populationPerHousehold\",\n",
    "            \"bedroomsPerRoom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the `input_data` \n",
    "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "\n",
    "# Replace `df` with the new DataFrame\n",
    "df = spark.createDataFrame(input_data, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|4.526|[129.0,322.0,8.32...|\n",
      "|3.585|[1106.0,2401.0,8....|\n",
      "|3.521|[190.0,496.0,7.25...|\n",
      "|3.413|[235.0,558.0,5.64...|\n",
      "|3.422|[280.0,565.0,3.84...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|     features_scaled|\n",
      "+-----+--------------------+--------------------+\n",
      "|4.526|[129.0,322.0,8.32...|[0.30623297630686...|\n",
      "|3.585|[1106.0,2401.0,8....|[2.62553233949916...|\n",
      "|3.521|[190.0,496.0,7.25...|[0.45104081781631...|\n",
      "|3.413|[235.0,558.0,5.64...|[0.55786627466754...|\n",
      "|3.422|[280.0,565.0,3.84...|[0.66469173151877...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the `standardScaler`\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the DataFrame to the scaler\n",
    "scaler = standardScaler.fit(df)\n",
    "\n",
    "# Transform the data in \"df\" with the scaler\n",
    "scaled_df = scaler.transform(df)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train, test = scaled_df.randomSplit([.8, .2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the argument elasticNetParam corresponds to α or the vertical \n",
    "# intercept and that the regParam or the regularization paramater corresponds to λ.\n",
    "\n",
    "# Initialize `lr`\n",
    "lr = LinearRegression(labelCol=\"label\", maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
    "# Fit the data to the model\n",
    "linearModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "pred = linearModel.transform(test)\n",
    "\n",
    "# Extract predictions and labels\n",
    "predictions = pred.select(\"prediction\").rdd.map(lambda x: x[0])\n",
    "labels = pred.select(\"label\").rdd.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.133339359890201, 0.14999),\n",
       " (1.448056941581123, 0.14999),\n",
       " (1.5709834297182181, 0.14999),\n",
       " (1.7494269579295185, 0.283),\n",
       " (1.2432540600023263, 0.366)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zip `predictions` and `labels` into a list\n",
    "predictionsAndLabel = predictions.zip(labels).collect()\n",
    "\n",
    "predictionsAndLabel[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0, 0.2798, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients for the model\n",
    "linearModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833539100326277"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intercept for the model\n",
    "linearModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764168687315352"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "linearModel.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42297595562448176"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R²\n",
    "linearModel.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (spark)",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
